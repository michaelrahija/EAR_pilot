sigma = 1/12
n = 1000
(sigma * sigma)/sqrt(n)
1/12
mean + ((qnorm(.95) * sigma) / sqrt(100)) # I think this isn't correct, not sure why
mean = 1100
sigma = 75
mean + ((qnorm(.95) * sigma) / sqrt(100))
sigma = 1/12
n = 1000
(sigma * sigma)/n
sigma/n
?round
round(sigma/n, 8)
round(sigma2/n, 2) # the
sigma2 = 1/12
n = 1000
round(sigma2/n, 2) # the
round(sigma2/n, 10) # the
1/12
ppois(10, lambda = 5*10)
ppois(10, lambda = 5*3)
#10:
p =.5
p(1-p)
p =.5
p (1-p)
prob =.5
prob*(1-prob)
expectedX <- -1 *.5 + 1*.5
expectedX2 <- (-1)^2*.5 + 1*.5
expectedX2 - expectedX
pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE)
qnorm(.95, mean = 1100, sd = 75)
var <- 1/12
var/sqrt(10)
pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE)
pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE)
pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE)
pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE)+pbinom(5, size = 5, prob = 0.5, lower.tail = FALSE)
pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE)
pbinom(5, size = 5, prob = 0.5, lower.tail = FALSE)
pbinom(5, size = 5, prob = 0.5, lower.tail = FALSE)
pbinom(5, size = 5, prob = 0.5, lower.tail = FALSE)
x<-choose(4,5)*.5*5
x
x<-choose(5,4)*.5*5
x
x<-choose(5,4)* .5^5
x
y<- choose(5,5) * .5^5
x+y
?pbinom
rbinom(4,size = 5, prob = 0.5, lower.tail = FALSE)
rbinom(4,size = 5, prob = 0.5)
x<-choose(5,4)* .5^5
y<- choose(5,5) * .5^5
x+y
ppois(10, lambda = 5*3) # fewer than 10, mean is 5, period are 3
prob <- .5
factorial(5)
x <- factorial(5)/factorial(5)
x * prob^5 * (1-prob)^4
qnorm(93, mean = 100, sd = 10)
?qnorm
pnorm(93, mean = 100, sd = 10)
qnorm(.95, mean = 100, sd = 10)
qnorm(.95, mean = 100, sd = 10/sqrt(50))
x<-choose(6,5)* .5^5
y<- choose(6,6) * .5^5
x+y
pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE)
round(pbinom(4, size = 5, prob = 0.5, lower.tail = FALSE))
round(pbinom(4, prob = .5, size = 6, lower.tail = FALSE)
)
round(pbinom(4, prob = .5, size = 6, lower.tail = FALSE) * 100, 1)
library(datasets)
library(ggplot2)
data <- ToothGrowth
g<- ggplot(data, aes(dose, len, color=supp))
g + geom_point()+geom_smooth(method= "lm")+ labs(title = "Tooth Length by dose and supplement",x="Length",y="Dose")
means<- c()
for (factors in as.character(unique(data$supp))){
for (doses in unique(data$dose)){
mean <- mean(data[data$supp == factors & data$dose == doses,1])
means <- append(means,mean)
}
}
table <- matrix(means,nrow = 3, ncol = 2)
table<- data.frame(table)
colnames(table) <- c("VC", "OJ")
row.names(table) <- c(".5", "1", "2")
table
install.packages(UsingR)
install.packages("UsingR")
library(UsingR)
data(father.son)
?UsingR
UsingR
summary(data)
mean(data[data$does = .5])
mean(data[data$dose = .5])
class(data$dose)
unique(data$does)
mean(data[data$dose = .5,])
mean(data[data$dose = .5,data$len])
mean(data[data$dose == .5,data$len])
lowdose = data[data$dose == .5, data$len]
data$dose
data[data$dose==.5,]
data[data$dose == .5,1]
lowdose = mean(data[data$dose == .5, 1])
meddose = mean(data[data$dose == 1, 1])
highdoes = mean(data[data$dose == 2, 1])
lowdose
meddose
highdoes
highdose
highdose = mean(data[data$dose == 2, 1])
?table
means <- c(lowdose, meddose,highdose)
means
t.test(highdose - lowdose)
lowdose = data[data$dose == .5, 1]
meddose = mean(data[data$dose == 1, 1])
highdose = data[data$dose == 2, 1]
t.test(highdose - lowdose)
means
lowdose = data[data$dose == .5, 1]
meddose = data[data$dose == 1, 1]
highdose = data[data$dose == 2, 1]
means <- c(mean(lowdose), mean(meddose), mean(highdose))
means
?t.test
library(datasets)
dataC <- data(ChickWeight); library (reshape)
head(dataC)
dataC <- data(ChickWeight); library (reshape); library(dplyr)
install.packages("dplyr")
dataC <- data(ChickWeight); library (reshape); library(dplyr)
head(dataC)
tail(dataC)
clasS(dataC)
class(dataC)
library(datasets)
dataC<-data(ChickWeight)
head(dataC)
dataC
summary(dataC)
dataC <- data(ChickWeight)
?data
data(ChickWeight)
wideCW <- dcast(ChickWeight, Diet + chick ~Time, value.var = "weight")
library(reshape2)
wideCW <- dcast(ChickWeight, Diet + chick ~Time, value.var = "weight")
library(dplyr)
wideCW <- dcast(ChickWeight, Diet + chick ~Time, value.var = "weight")
wideCW <- dcast(ChickWeight, Diet + Chick ~Time, value.var = "weight")
head(wideCW)
names(wideCW)[-(1:2)] <- paste("time", names(wideCW)[-(1:2)], sep="")
wideCW <- mutate(wideCW, gain = time21-time0)
head(wideCW)
head(data)
wideData <-(dcast(data, supp ~ dose, value.var = 'len'))
head(wideData)
wideData <-dcast(data, supp ~ dose, value.var = 'len')
wideData
wideData <-dcast(data, supp + dose, value.var = 'len')
wideData <-dcast(data, supp + len~dose )
wideData
head(data)
VCgain = data[data$len =="VC", data$dose == 2] - data[data$len =="VC", data$dose == 2]
VCgain = data[data$len =="VC"& data$dose == 2,1] - data[data$len =="VC"& data$dose == 2,1]
VCgain
data[data$len =="VC"& data$dose == 2,1]
VCgain = data[data$supp =="VC"& data$dose == 2,1] - data[data$sup =="VC"& data$dose == 2,1]
VCgain = data[data$supp =="VC"& data$dose == 2,1] - data[data$supp =="VC"& data$dose == 2,1]
VCgain
VCgain = data[data$supp =="VC"& data$dose == 2,1] - data[data$supp =="VC"& data$dose == .5,1]
VCgain
OJgain = data[data$supp =="OJ"& data$dose == 2,1] - data[data$supp =="OJ"& data$dose == .5,1]
t.test(OJgain - VCgain )
?t.test
t.test(OJgain - VCgain, alternative = c("greater"))
pbinom(3,size=4,prob = .5)
1-pbinom(3, size= 4 ,prob = .5)
1-pbinom(3, size= 4 ,prob = .5, lower.tail = FALSE)
pbinom(3, size= 4 ,prob = .5, lower.tail = FALSE)
Qbinom(3, size= 4 ,prob = .5, lower.tail = FALSE)
qbinom(3, size= 4 ,prob = .5, lower.tail = FALSE)
pbinom(3, size= 4 ,prob = .75, lower.tail = FALSE)
pbinom(2, size= 4 ,prob = .75, lower.tail = FALSE)
pbinom(2, size= 4 ,prob = .5, lower.tail = FALSE)
10/1787
10/1787
n <- 18
variance<- c(1.5^2,1.8^2)
sp <- sqrt(mean(variances)) #same number of observations # pooled SE
-3 - 1.5 + c(-1,1) * qt(.975,n-2) * sp * (1/9 + 1/9)^.5
n <- 18
variances<- c(1.5^2,1.8^2)
sp <- sqrt(mean(variances)) #same number of observations # pooled SE
-3 - 1.5 + c(-1,1) * qt(.975,n-2) * sp * (1/9 + 1/9)^.5
?ppois
#is the one-sided p-value that the test is below the standard?
bench = 1/100
observed = 10/1787
ppois(observed, bench, lower.tail=FALSE)
#is the one-sided p-value that the test is below the standard?
bench = (1/100) * 100000
observed = (10/1787) * 100000
ppois(observed-1, bench, lower.tail=TRUE)
list<- ('Ai Marmi', "Holy ham", "Sapore di Principe")
sample(list, 2)
list<- c('Ai Marmi', "Holy ham", "Sapore di Principe")
sample(list, 2)
450*120
151*20
151*20*1.27
a<-151*20
a*1.27
install.packages("rvest")
library(rvest)
vignette("selectorgadget")
library(rvest)
cast<- html_nodes(html, ".itemprop .itemprop")
html <- html("http://www.imdb.com/title/tt1490017/")
cast<- html_nodes(html, ".itemprop .itemprop")
cast
cast <- html_nodes(html, "#titleCast span.itemprop")
cast
cast<- html_nodes(html, ".itemprop .itemprop")
length(cast)
html_text(cast)
html <- html("http://www.casa.it/vendita-residenziale/immobile-appartamento-in-bologna%2f+nomentano%2c+roma%2c+rm%2c+lazio%3b+/lista-1?preferredState=laz&includeSurrounding=false&persistIncludeSurrounding=true&source=mapdrilldown")
html <- html("http://www.immobiliare.it/Roma/vendita_case-Roma.html")
prices <- html_nodes(html, ".price")
prices
prices <- html_text(prices)
prices
all <- html_nodes(html, '.align_left')
all
x <- html_text(all)
x
html <- html("http://www.immobiliare.it/Roma/vendita_case-Roma.html")
all <- html_nodes(html, 'span')
x <- html_text(all)
x
all <- html_nodes(html, 'span:nth-child(4)')
html_text(all)
length(prices)
attempt <- html_nodes(html, '#annunciContainer .align_left")
attempt <- html_nodes(html, '#annunciContainer .align_left")
attempt <- html_nodes(html, "#annunciContainer .align_left")
html_text(attempt)
daily <- 200*1.18
daily
daily * 18
mmonthly <- 4700 * 1.18
lmonthly <- daily * 18
hh <- mmonthly + lmonthly
hh
hh*12
61697-5025
61697-50025
61697-50025
61697-60025
1672/60025
330*20*11
330*20
6600/1.5
200*1.15
230*20
200*18
200*18
3600+4600
8200*1.15
8200*1.15*11
300*20
square <- function(x) x*X
square(4)
square <- function(x) x*x
square(4)
sapply(1:100,square)
sample = as.data.frame(sample = sapply(1:100,square))
sample = as.data.frame(sapply(1:100,square)
)
sample
library(ggplot2)
ggplot(sample)
sample
x=1:100
sample = cbind(sample,x)
head(sample)
ggplot(sample)
ggplot(sampleaes(x = x, y = y))
ggplot(sample,aes(x = x, y = y))
install.packages("knitr")
path = "T:/Team_working_folder/G/11. Research/07-CROP-1&2-AreaYieldProdn-MixedContRepCrops/Monitoring_notebook.xlsx"
#
library(XLConnect)
#countries
countries = readNamedRegionFromFile(path, name= 'countries', header=TRUE)
countries.t = subset(countries, Name != "NA")
#Code to implement table selection
if (is.na(countries[1,1])){
print("countries not choosen yet!")}
#filter columns for when there's information
if (!is.na(countries[1,1])){
id.na <- sapply(countries.t[1,],is.na)
index <- length(countries.t)  - sum(id.na)
countries.t[,c(1,3:index)]
}
path = "T:/Team_working_folder/G/11. Research/07-CROP-4-HorticulturalCrops/Monitoring_notebook.xlsx"
#countries
countries = readNamedRegionFromFile(path, name= 'countries', header=TRUE)
countries.t = subset(countries, Name != "NA")
#Code to implement table selection
if (is.na(countries[1,1])){
print("countries not choosen yet!")}
#filter columns for when there's information
if (!is.na(countries[1,1])){
id.na <- sapply(countries.t[1,],is.na)
index <- length(countries.t)  - sum(id.na)
countries.t[,c(1,3:index)]
}
countries = readNamedRegionFromFile(path, name= 'countries', header=TRUE)
countries.t = subset(countries, Country != "NA")
countries = readNamedRegionFromFile(path, name= 'countries', header=TRUE)
countries
colnames(countries) <- ("Country", "contact","email","status","comment")
colnames(countries) <- c("Country", "contact","email","status","comment")
countries.t = subset(countries, Country != "NA")
countries.t
path = "T:/Team_working_folder/G/11. Research/07-CROP-4-HorticulturalCrops/Monitoring_notebook.xlsx"
#countries
countries = readNamedRegionFromFile(path, name= 'countries', header=TRUE)
colnames(countries) <- c("country", "contact","email","status","comment")
countries.t = subset(countries, Country != "NA")
#Code to implement table selection
if (is.na(countries[1,1])){
print("countries not choosen yet!")}
#filter columns for when there's information
if (!is.na(countries[1,1])){
id.na <- sapply(countries.t[1,],is.na)
index <- length(countries.t)  - sum(id.na)
countries.t[,c(1,3:index)]
}
countries.t[,c(1,4)]
sum(c(1,4,6))
install.packages(xtable)
install.packages("xtable")
3750/8
3750/600
600*7
3750/580
580*6
580*7
3750/550
550*7
550*7
151-135
install.packages("tidyr")
install.package("sampling")
install.packages("sampling")
550*7
30000/550
56*550
55*550
54*550
library(data)
install.packages("data")
data(belgianmunicipalities)
?data
data(belgianmunicipalities)
library(sampling)
data(belgianmunicipalities)
head(belgianmunicipalities)
?belgianmunicipalities
?inclusionprobabilities
data(belgianmunicipalities)
pik=inclusionprobabilities(belgianmunicipalities$Tot04,200)
# the first-order inclusion probabilities for each municipality
data.frame(pik=pik,name=belgianmunicipalities$Commune)
# the inclusion probability sum is equal to the sample size
sum(pik)
install.packages("rvest")
229*300
devtools::install_github("UNFAOstatistics/faodoc")
devtools::install_github("UNFAOstatistics/faodoc")
library(dplyr)
library(xlsx)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(data.table)
library(maps)
library(countrycode)
library(scales)
sys <- Sys.info()
if(sys[7] == "josh"){
dir = "~/Documents/Github/EAR_pilot/"
} else if(sys[5] == "x86_64"){
dir = "~/Dropbox/FAO_ESS_STUFF/EAR_pilot" #Mac
data.dir = "~/Dropbox/FAO_ESS_STUFF/EAR_pilot_data/"
} else if (sys[5] == "Michael"){
dir = "C:/Users/Michael/Dropbox/FAO_ESS_STUFF/EAR_pilot"#HOME PC
data.dir = "C:/Users/Michael/Dropbox/FAO_ESS_STUFF/EAR_pilot_data/"
} else if (sys[6]=="Rahija") {
dir = "C:/Users/rahija/Dropbox/FAO_ESS_STUFF/EAR_pilot" #FAO PC
data.dir = "C:/Users/rahija/Dropbox/FAO_ESS_STUFF/EAR_pilot_data/"
} else {
stop("Implement location for current user!")
}
setwd(dir)
data <- read.csv(paste0(data.dir,"relevant_variables2.csv"), stringsAsFactors = FALSE)
## Clean data set, and filter for operationnaly active
source("R/cleanAndFilterFPMIS.R")
data.o <- cleanAndFilterFPMIS(data, ActiveOnly = FALSE)
##clean up project titles
data.o$ProjectTitle <- gsub("Å½","Ã©", data.o$ProjectTitle)
data.o$ProjectTitle <- gsub("ciân","ciÃ³n", data.o$ProjectTitle)
data.o$ProjectTitle <- gsub("mise en .*uvre ","mise en ouvre ", data.o$ProjectTitle)
## Add staff column
data.o$staff <- paste(data.o$ProjectStaffBudgetHolder,
data.o$ProjectStaffLTOOfficer,
data.o$ProjectStaffLTUOfficer,
data.o$ProjectStaffProgrammeAssistance)
# data.o <- addTeam(data.o)
## Show overview of projects by status
tab <- data.o %>%
group_by(ProjectStatus, ProjectClassification) %>%
summarize(Number = length(ProjectTitle))
tab <- spread(tab, ProjectClassification, Number, fill = 0)
write.csv(data.o, file = "filexLeslie.csv")
